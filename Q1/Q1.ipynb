{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Samyak\n",
      "[nltk_data]     Jain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Samyak\n",
      "[nltk_data]     Jain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import string\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../Humor,Hist,Media,Food'\n",
    "file_names = os.listdir(data_dir)\n",
    "file_paths = [(data_dir + '/' + fname) for fname in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def read_files(fpaths):\n",
    "    file_tokens = []\n",
    "    for fpath in fpaths:\n",
    "        f = open(fpath, 'r', encoding='utf-8', errors='replace')\n",
    "        ftxt_unprocessed = f.read()\n",
    "        # print(ftxt_unprocessed)\n",
    "        ftoks = preprocess(ftxt_unprocessed)\n",
    "        file_tokens.append(ftoks)\n",
    "    return file_tokens\n",
    "\n",
    "def isValidTok(tok):\n",
    "    if((tok not in string.punctuation) and (tok.isnumeric() == False) and (sum([0 if ch in string.punctuation else 1 for ch in tok]) >= 1)):\n",
    "        return True\n",
    "    return False \n",
    "\n",
    "def preprocess(file_text):\n",
    "\n",
    "    all_tokens = word_tokenize(file_text.lower())\n",
    "    all_unique_tokens = set(all_tokens)\n",
    "    tokens = list(all_unique_tokens - stop_words)\n",
    "    # ps = PorterStemmer()\n",
    "    valid_toks = []\n",
    "    for tok in tokens:\n",
    "        if(isValidTok(tok) == True):\n",
    "            valid_toks.append(tok)\n",
    "    return valid_toks\n",
    "    # print(final_tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_toks = read_files(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inverted_index(file_toks):\n",
    "    inv_index = {}\n",
    "    for i in range(len(file_toks)):\n",
    "        for tok in file_toks[i]:\n",
    "            if(tok not in inv_index.keys()):\n",
    "                inv_index[tok] = [i]\n",
    "            else:\n",
    "                inv_index[tok].append(i)\n",
    "    inv_index = dict(sorted(inv_index.items()))\n",
    "    terms_list = inv_index.keys()\n",
    "    for word in terms_list:\n",
    "        inv_index[word].sort()\n",
    "    return inv_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDocsFromID(file_names, doc_IDs):\n",
    "    doc_names = []\n",
    "    for doc_ID in doc_IDs:\n",
    "        doc_names.append(file_names[doc_ID])\n",
    "    return doc_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_AND(inv_index, term1, term2):\n",
    "\n",
    "    terms_list = inv_index.keys()\n",
    "\n",
    "    if((term1 not in terms_list) or (term2 not in terms_list)):\n",
    "        return []\n",
    "\n",
    "    posting1 = inv_index[term1]\n",
    "    posting2 = inv_index[term2]\n",
    "    ptr1 = 0\n",
    "    ptr2 = 0\n",
    "    answer = []\n",
    "\n",
    "    num_comparisons = 0\n",
    "\n",
    "    while(ptr1 < len(posting1) and ptr2 < len(posting2)):\n",
    "        num_comparisons += 1\n",
    "        # print(f\"1 : {posting1[ptr1]} , 2: {posting2[ptr2]}\")\n",
    "\n",
    "        if(posting1[ptr1] == posting2[ptr2]):\n",
    "            answer.append(posting1[ptr1])\n",
    "            ptr1 += 1\n",
    "            ptr2 += 1\n",
    "        elif(posting1[ptr1] < posting2[ptr2]):\n",
    "            ptr1 += 1\n",
    "        else:\n",
    "            ptr2 += 1\n",
    "    return num_comparisons, answer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = create_inverted_index(file_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 9, 18, 21, 29, 34, 35, 38, 43, 44, 46, 51, 55, 56, 58, 60, 63, 64, 67, 69, 70, 74, 75, 85, 91, 97, 106, 108, 109, 121, 123, 124, 127, 128, 129, 131, 133, 134, 138, 139, 140, 145, 146, 147, 149, 150, 152, 156, 159, 167, 168, 169, 174, 175, 178, 179, 181, 184, 186, 187, 214, 219, 225, 226, 228, 229, 232, 233, 234, 235, 239, 240, 246, 252, 256, 257, 268, 282, 284, 288, 297, 300, 315, 316, 321, 324, 328, 329, 330, 331, 340, 343, 344, 349, 351, 352, 354, 360, 362, 365, 367, 369, 372, 376, 378, 379, 382, 384, 385, 390, 391, 392, 393, 397, 399, 400, 401, 404, 405, 408, 418, 429, 430, 431, 436, 439, 441, 443, 450, 453, 455, 457, 470, 479, 483, 488, 489, 494, 501, 504, 510, 511, 513, 517, 518, 519, 520, 531, 532, 533, 534, 537, 538, 541, 543, 546, 547, 548, 549, 552, 557, 565, 574, 579, 584, 594, 601, 608, 610, 611, 622, 625, 630, 632, 635, 641, 642, 648, 649, 658, 662, 663, 668, 670, 672, 674, 687, 701, 706, 707, 713, 715, 719, 724, 730, 734, 738, 744, 747, 748, 749, 752, 760, 762, 764, 767, 770, 773, 780, 781, 784, 785, 789, 790, 791, 792, 803, 808, 809, 811, 812, 813, 814, 817, 837, 842, 846, 847, 851, 855, 866, 869, 870, 871, 872, 874, 875, 876, 877, 878, 881, 882, 892, 904, 911, 914, 923, 926, 927, 928, 930, 937, 941, 945, 946, 971, 975, 977, 980, 984, 985, 1009, 1013, 1014, 1016, 1017, 1021, 1022, 1029, 1031, 1033, 1034, 1036, 1039, 1043, 1044, 1052, 1057, 1059, 1063, 1065, 1070, 1072, 1073, 1078, 1087, 1090, 1091, 1097, 1101, 1102, 1105, 1109, 1115, 1119, 1120, 1128, 1131, 1132]\n"
     ]
    }
   ],
   "source": [
    "print(inverted_index['water'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 6, 9, 35, 42, 44, 55, 57, 58, 63, 67, 73, 88, 89, 119, 120, 121, 127, 135, 137, 140, 173, 175, 184, 190, 191, 192, 193, 197, 200, 228, 231, 243, 247, 250, 253, 259, 267, 278, 281, 286, 289, 295, 315, 324, 339, 344, 345, 351, 352, 353, 362, 376, 380, 381, 392, 398, 423, 424, 428, 434, 439, 441, 451, 469, 483, 501, 503, 505, 537, 577, 582, 583, 592, 594, 606, 611, 616, 630, 641, 644, 655, 663, 667, 669, 672, 706, 709, 713, 715, 736, 742, 749, 753, 761, 766, 781, 787, 791, 806, 812, 813, 814, 815, 816, 817, 840, 846, 855, 858, 890, 913, 942, 949, 957, 968, 977, 989, 1012, 1030, 1035, 1040, 1069, 1070, 1088, 1106, 1120]\n"
     ]
    }
   ],
   "source": [
    "print(inverted_index['effect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp, ans = query_AND(inverted_index, 'water', 'effect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 9, 35, 44, 55, 58, 63, 67, 121, 127, 140, 175, 184, 228, 315, 324, 344, 351, 352, 362, 376, 392, 439, 441, 483, 501, 537, 594, 611, 630, 641, 663, 672, 706, 713, 715, 749, 781, 791, 812, 813, 814, 817, 846, 855, 977, 1070, 1120]\n"
     ]
    }
   ],
   "source": [
    "print(ans)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2370e07001db70a9c24f7e21173c51fbc4321340913a02830aed4885459fa0a0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
